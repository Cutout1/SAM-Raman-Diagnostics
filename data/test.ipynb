{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdewy\\MIT\\SAM-RamanDiagnostics\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "test = np.load('utils/splits.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array({1: [[4, 0, 1, 2, 3], [1, 4, 2, 0, 3], [3, 4, 1, 0, 2], [0, 2, 3, 4, 1], [0, 4, 1, 2, 3]], 2: [[2, 1, 4, 0, 3], [1, 2, 0, 4, 3], [4, 2, 0, 3, 1], [3, 2, 1, 4, 0], [0, 1, 2, 3, 4]], 3: [[3, 2, 0, 4, 1], [2, 4, 0, 1, 3], [2, 1, 4, 3, 0], [1, 0, 4, 2, 3], [2, 0, 4, 1, 3]], 4: [[2, 1, 3, 4, 0], [4, 0, 3, 1, 2], [1, 3, 0, 4, 2], [3, 0, 1, 4, 2], [0, 2, 1, 3, 4]], 5: [[2, 4, 0, 3, 1], [1, 0, 4, 3, 2], [4, 0, 2, 1, 3], [1, 3, 2, 0, 4], [0, 4, 2, 1, 3]], 6: [[4, 2, 0, 1, 3], [3, 0, 4, 2, 1], [0, 1, 4, 2, 3], [4, 3, 1, 2, 0], [3, 2, 0, 1, 4]], 7: [[4, 0, 2, 3, 1], [2, 1, 3, 0, 4], [0, 2, 4, 1, 3], [1, 0, 4, 3, 2], [0, 2, 3, 4, 1]], 8: [[4, 1, 3, 2, 0], [0, 4, 1, 2, 3], [1, 0, 2, 3, 4], [3, 2, 4, 1, 0], [3, 2, 1, 4, 0]], 9: [[3, 0, 4, 2, 1], [4, 1, 2, 3, 0], [1, 0, 2, 4, 3], [0, 4, 3, 1, 2], [2, 3, 0, 1, 4]], 10: [[3, 2, 4, 1, 0], [0, 1, 3, 2, 4], [0, 4, 2, 1, 3], [4, 1, 3, 2, 0], [1, 0, 2, 4, 3]]},\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = f'{args.prostate_mask*\"pro-\"}{args.model}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 \n",
      "Split:\n",
      " [[4, 0, 1, 2, 3], [1, 4, 2, 0, 3], [3, 4, 1, 0, 2], [0, 2, 3, 4, 1], [0, 4, 1, 2, 3]]\n",
      "Trial 2 \n",
      "Split:\n",
      " [[2, 1, 4, 0, 3], [1, 2, 0, 4, 3], [4, 2, 0, 3, 1], [3, 2, 1, 4, 0], [0, 1, 2, 3, 4]]\n",
      "Trial 3 \n",
      "Split:\n",
      " [[3, 2, 0, 4, 1], [2, 4, 0, 1, 3], [2, 1, 4, 3, 0], [1, 0, 4, 2, 3], [2, 0, 4, 1, 3]]\n",
      "Trial 4 \n",
      "Split:\n",
      " [[2, 1, 3, 4, 0], [4, 0, 3, 1, 2], [1, 3, 0, 4, 2], [3, 0, 1, 4, 2], [0, 2, 1, 3, 4]]\n",
      "Trial 5 \n",
      "Split:\n",
      " [[2, 4, 0, 3, 1], [1, 0, 4, 3, 2], [4, 0, 2, 1, 3], [1, 3, 2, 0, 4], [0, 4, 2, 1, 3]]\n",
      "Trial 6 \n",
      "Split:\n",
      " [[4, 2, 0, 1, 3], [3, 0, 4, 2, 1], [0, 1, 4, 2, 3], [4, 3, 1, 2, 0], [3, 2, 0, 1, 4]]\n",
      "Trial 7 \n",
      "Split:\n",
      " [[4, 0, 2, 3, 1], [2, 1, 3, 0, 4], [0, 2, 4, 1, 3], [1, 0, 4, 3, 2], [0, 2, 3, 4, 1]]\n",
      "Trial 8 \n",
      "Split:\n",
      " [[4, 1, 3, 2, 0], [0, 4, 1, 2, 3], [1, 0, 2, 3, 4], [3, 2, 4, 1, 0], [3, 2, 1, 4, 0]]\n",
      "Trial 9 \n",
      "Split:\n",
      " [[3, 0, 4, 2, 1], [4, 1, 2, 3, 0], [1, 0, 2, 4, 3], [0, 4, 3, 1, 2], [2, 3, 0, 1, 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "splits = np.load('utility/splits.npy',allow_pickle=True).tolist()\n",
    "X_2018 = np.load('data/spectral_data/X_2018clinical.npy')\n",
    "y_2018 = np.load('data/spectral_data/y_2018clinical.npy')\n",
    "X_2019 = np.load('data/spectral_data/X_2019clinical.npy')\n",
    "y_2019 = np.load('data/spectral_data/y_2019clinical.npy')\n",
    "\n",
    "list_trials = np.arange(10)\n",
    "\n",
    "mapping = {0.0:0, 2.0:1, 3.0:2, 5.0:3, 6.0:4}\n",
    "y_2018_map = [mapping[num] for num in y_2018]\n",
    "y_2019_map = [mapping[num] for num in y_2019]\n",
    "\n",
    "for trial, split in splits.items():\n",
    "    if trial not in list_trials:\n",
    "        continue\n",
    "    print('Trial', trial, '\\nSplit:\\n', split)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "    for idx, i in enumerate(range(0, len(y_2018_map), 2000)):\n",
    "        for num in split[idx][:3]:\n",
    "            X_train.extend(X_2018[i+num*400:i+num*400+400])\n",
    "            y_train.extend(y_2018_map[i+num*400:i+num*400+400])\n",
    "\n",
    "        val_num = split[idx][3]\n",
    "        X_val.extend(X_2019[i+val_num*400:i+val_num*400+400])\n",
    "        y_val.extend(y_2019_map[i+val_num*400:i+val_num*400+400])\n",
    "\n",
    "        test_num = split[idx][4]\n",
    "        X_test.extend(X_2018[i+test_num*400:i+test_num*400+400])\n",
    "        y_test.extend(y_2018_map[i+test_num*400:i+test_num*400+400])\n",
    "\n",
    "    for idx, i in enumerate(range(0, len(y_2019_map), 500)):\n",
    "        for num in split[idx][:3]:\n",
    "            X_train.extend(X_2019[i+num*100:i+num*100+100])\n",
    "            y_train.extend(y_2019_map[i+num*100:i+num*100+100])\n",
    "\n",
    "        val_num = split[idx][3]\n",
    "        X_val.extend(X_2019[i+val_num*100:i+val_num*100+100])\n",
    "        y_val.extend(y_2019_map[i+val_num*100:i+val_num*100+100])\n",
    "\n",
    "        test_num = split[idx][4]\n",
    "        X_test.extend(X_2019[i+test_num*100:i+test_num*100+100])\n",
    "        y_test.extend(y_2019_map[i+test_num*100:i+test_num*100+100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for idx, num in enumerate(np.unique(y_2018)):\n",
    "    mapping[idx] = num\n",
    "\n",
    "for i in mapping:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(y_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 \n",
      "Split:\n",
      " [[4, 0, 1, 2, 3], [1, 4, 2, 0, 3], [3, 4, 1, 0, 2], [0, 2, 3, 4, 1], [0, 4, 1, 2, 3]]\n",
      "1200 1600\n",
      "1200 1600\n",
      "800 1200\n",
      "400 800\n",
      "1200 1600\n",
      "300 400\n",
      "300 400\n",
      "200 300\n",
      "100 200\n",
      "300 400\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_path = ['data/spectral_data/y_2018clinical.npy', 'data/spectral_data/y_2019clinical.npy']\n",
    "spectra_path = ['data/spectral_data/X_2018clinical.npy', 'data/spectral_data/X_2019clinical.npy']\n",
    "spectra_interval = [400, 100]\n",
    "splits = np.load('utility/splits.npy',allow_pickle=True).tolist()\n",
    "list_trials = np.arange(10)\n",
    "#spectra_path = 'data/spectral_data/X_2018clinical.npy'\n",
    "#spectra_intervals = 2000\n",
    "#label_path = 'data/spectral_data/y_2018clinical.npy'\n",
    "\n",
    "assert len(spectra_path) == len(label_path) == len(spectra_interval), 'Spectra, labels, and invervals do not align.'\n",
    "\n",
    "for trial, split in splits.items():\n",
    "    if trial not in list_trials:\n",
    "        continue\n",
    "    print('Trial', trial, '\\nSplit:\\n', split)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "\n",
    "    #if type(spectra_path) == list:\n",
    "    for spectra, label, interval in zip(spectra_path, label_path, spectra_interval):\n",
    "        X = np.load(spectra)\n",
    "        y = np.load(label)\n",
    "\n",
    "        for i, l in enumerate(np.unique(y)):\n",
    "            idxs = split[i]\n",
    "            X_type = X[y==l]\n",
    "\n",
    "            for num in idxs[:-2]:\n",
    "                X_train.extend(X_type[num*interval:num*interval+interval])\n",
    "                y_train.extend([i]*interval)\n",
    "\n",
    "            val_num = idxs[-2]\n",
    "            X_val.extend(X_type[val_num*interval:val_num*interval+interval])\n",
    "            y_val.extend([i]*interval)\n",
    "\n",
    "            test_num = idxs[-1]\n",
    "            X_test.extend(X_type[test_num*interval:test_num*interval+interval])\n",
    "            y_test.extend([i]*interval)\n",
    "\n",
    "            print(test_num*interval, test_num*interval+interval)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 7500, 2500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test), len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(y):\n",
    "    dist = {}\n",
    "    for i in y:\n",
    "        if i in dist:\n",
    "            dist[i] += 1\n",
    "        else:\n",
    "            dist[i] = 1\n",
    "\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 500, 1: 500, 2: 500, 3: 500, 4: 500}\n"
     ]
    }
   ],
   "source": [
    "get_dist(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 \n",
      "Split:\n",
      " [[4, 0, 1, 2, 3], [1, 4, 2, 0, 3], [3, 4, 1, 0, 2], [0, 2, 3, 4, 1], [0, 4, 1, 2, 3]]\n",
      "1200 1600\n",
      "1200 1600\n",
      "800 1200\n",
      "400 800\n",
      "1200 1600\n",
      "300 400\n",
      "300 400\n",
      "200 300\n",
      "100 200\n",
      "300 400\n"
     ]
    }
   ],
   "source": [
    "from spectral import Spectral\n",
    "\n",
    "splits = np.load('utility/splits.npy',allow_pickle=True).tolist()\n",
    "X_2018 = np.load('data/spectral_data/X_2018clinical.npy')\n",
    "y_2018 = np.load('data/spectral_data/y_2018clinical.npy')\n",
    "X_2019 = np.load('data/spectral_data/X_2019clinical.npy')\n",
    "y_2019 = np.load('data/spectral_data/y_2019clinical.npy')\n",
    "\n",
    "mapping = {0.0:0, 2.0:1, 3.0:2, 5.0:3, 6.0:4}\n",
    "y_2018_map = [mapping[num] for num in y_2018]\n",
    "y_2019_map = [mapping[num] for num in y_2019]\n",
    "\n",
    "for trial, split in splits.items():\n",
    "    print('Trial', trial, '\\nSplit:\\n', split)\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "    for idx, i in enumerate(range(0, len(y_2018_map), 2000)):\n",
    "        for num in split[idx][:3]:\n",
    "            X_train.extend(X_2018[i+num*400:i+num*400+400])\n",
    "            y_train.extend(y_2018_map[i+num*400:i+num*400+400])\n",
    "\n",
    "        val_num = split[idx][3]\n",
    "        X_val.extend(X_2019[i+val_num*400:i+val_num*400+400])\n",
    "        y_val.extend(y_2019_map[i+val_num*400:i+val_num*400+400])\n",
    "\n",
    "        test_num = split[idx][4]\n",
    "        X_test.extend(X_2018[i+test_num*400:i+test_num*400+400])\n",
    "        y_test.extend(y_2018_map[i+test_num*400:i+test_num*400+400])\n",
    "\n",
    "        print(test_num*400, test_num*400+400)\n",
    "\n",
    "    for idx, i in enumerate(range(0, len(y_2019_map), 500)):\n",
    "        for num in split[idx][:3]:\n",
    "            X_train.extend(X_2019[i+num*100:i+num*100+100])\n",
    "            y_train.extend(y_2019_map[i+num*100:i+num*100+100])\n",
    "\n",
    "        val_num = split[idx][3]\n",
    "        X_val.extend(X_2019[i+val_num*100:i+val_num*100+100])\n",
    "        y_val.extend(y_2019_map[i+val_num*100:i+val_num*100+100])\n",
    "\n",
    "        test_num = split[idx][4]\n",
    "        X_test.extend(X_2019[i+test_num*100:i+test_num*100+100])\n",
    "        y_test.extend(y_2019_map[i+test_num*100:i+test_num*100+100])\n",
    "\n",
    "        print(test_num*100, test_num*100+100)\n",
    "\n",
    "        spectral_batch_size = 16\n",
    "        spectral_workers = 2\n",
    "        dataset = Spectral(X_train, y_train, spectral_batch_size, spectral_workers, X_fn_t=X_test, y_fn_t=y_test, X_fn_v=X_val, y_fn_v=y_val)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are there any repeating arrays in arr? False\n"
     ]
    }
   ],
   "source": [
    "arr_tuples = [tuple(row) for row in X_val]\n",
    "\n",
    "# Step 2: Convert the set of tuples to a set to remove duplicates\n",
    "arr_set = set(arr_tuples)\n",
    "\n",
    "# Step 3: Count the number of unique arrays (rows)\n",
    "num_unique = len(arr_set)\n",
    "\n",
    "# Step 4: Check if the number of unique arrays is equal to the number of rows\n",
    "has_duplicates = num_unique != np.array(X_test).shape[0]\n",
    "\n",
    "print(f\"Are there any repeating arrays in arr? {has_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdewy\\MIT\\SAM-RamanDiagnostics\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 0, 1, 2, 3], [1, 4, 2, 0, 3], [3, 4, 1, 0, 2], [0, 2, 3, 4, 1], [0, 4, 1, 2, 3]]\n",
      "[0.00000000e+00 1.42582337e-05 2.25746151e-05 ... 9.99969043e-01\n",
      " 9.99975852e-01 1.00000000e+00]\n",
      "[4, 0, 1, 2, 3]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m spectra_interval \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m      7\u001b[0m splits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutility/splits.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m----> 9\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mRamanSpectra\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectra_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectra_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jdewy\\MIT\\SAM-RamanDiagnostics\\dataset.py:8\u001b[0m, in \u001b[0;36mRamanSpectra.__init__\u001b[1;34m(self, label_path, spectra_path, spectra_interval, split, shuffle, num_workers, batch_size, transform)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, label_path, spectra_path, spectra_interval, split, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(spectra_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(label_path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(spectra_interval), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpectra, labels, and invervals do not align.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m     X_train, X_val, X_test, y_train, y_val, y_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectra_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspectra_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m RamanSpectraDataset(X_train, y_train, transform)\n\u001b[0;32m     11\u001b[0m     val_dataset \u001b[38;5;241m=\u001b[39m RamanSpectraDataset(X_val, y_val, transform)\n",
      "File \u001b[1;32mc:\\Users\\jdewy\\MIT\\SAM-RamanDiagnostics\\dataset.py:28\u001b[0m, in \u001b[0;36mRamanSpectra._get_splits\u001b[1;34m(self, spectra_path, label_path, spectra_interval, split)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(split[i])\n\u001b[0;32m     27\u001b[0m idxs \u001b[38;5;241m=\u001b[39m split[i]\n\u001b[1;32m---> 28\u001b[0m X_type \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m idxs[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]:\n\u001b[0;32m     31\u001b[0m     X_train\u001b[38;5;241m.\u001b[39mextend(X_type[num\u001b[38;5;241m*\u001b[39minterval:num\u001b[38;5;241m*\u001b[39minterval\u001b[38;5;241m+\u001b[39minterval])\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "from dataset import RamanSpectra\n",
    "import numpy as np\n",
    "\n",
    "spectra_path = ['data/spectral_data/X_2018clinical.npy', 'data/spectral_data/X_2019clinical.npy']\n",
    "label_path = ['data/spectral_data/y_2018clinical.npy', 'data/spectral_data/y_2019clinical.npy']\n",
    "spectra_interval = [400, 100]\n",
    "splits = np.load('utility/splits.npy',allow_pickle=True).tolist()\n",
    "\n",
    "dataset = RamanSpectra(spectra_path, label_path, spectra_interval, splits[1], shuffle=True, num_workers=2, transform=None, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 0, 1, 2, 3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
